\part{Harnessing Quantum Systems}

\section{Lecture 10}

The previous lectures assumed that quantum systems were under our total control,
which is completely unrealistic.
For the next 50 years or so, there will likely be no meaningful systems that are completely within our control. Thus,
we turn our attention to figuring out how quantum systems act on their own, describing quantum noise and quantum error correction,
which has far-reaching consequences beyond just computing.
In our next chapter, we will discuss real-life experimental implementations of quantum computers in labs.

\subsection{Schrodinger's Equation}
As we claimed earlier, the (time) evolution of a quantum system is unitary.
\[ \ket{\psi(t_2)} = U(t_2, t_1) \ket{\psi(t_1)} \]
Furthermore, we should be able to compose these operators:
\[ \ket{\psi(t_3)} = U(t_3, t_2) U(t_2, t_1) \ket{\psi(t_1)} \implies U(t_3, t_1) = U(t_3, t_2) U(t_2, t_1) \]
Namely, we must have consistency of the quantum circuit. Thus, to know the evolution of our system, it is sufficient to know
how to take small steps of $\epsilon$, i.e. we only need $U(t + \epsilon, t)$. Intuitively, we should expect that the dynamics are small, i.e.
Taylor expandable as:
\[ U(t + \epsilon, t) = I - i\epsilon H(t) + O\qty(\epsilon^2) \]
But we know this matrix is unitary, so:
\[ I = U^{\dagger} U = \qty(I + i\epsilon H^{\dagger} + O\qty(\epsilon^2))\qty(I - i \epsilon H + O\qty(\epsilon^2)) = I + i \epsilon (H^{\dagger} - H) + O\qty(\epsilon^2) \]
For the left and right hand sides to agree, we must have $ i \epsilon \qty(H - H^{\dagger}) = 0$, or $H = H^{\dagger}$. This means $H$ is a \textbf{Hermitian matrix}, which
we can think of as a generalization of a symmetric matrix to the complex case. This means we can write our evolution as approximately:
\begin{align*}
    \ket{\psi(t + \epsilon)} &= (I + i\epsilon H(t)) \ket{\psi(t)} \\
    \frac{\ket{\psi(t + \epsilon)} - \ket{\psi(t)}}{\epsilon} &= - i H(t) \ket{\psi(t)} \\
    i \pdv{}{t} \ket{\psi(t)} &= H(t) \ket{\psi(t)}
\end{align*}
where we took a limit as $\epsilon \to 0$. This equation is referred to as \textbf{Schrodinger's Equation}, with unit $\hbar = 1$. We are often
interested in the special case where $H$ is a constant, i.e. the dynamics are time-homogenous with $U(t_2, t_1) = U(t_2 - t_1, 0)$.
This operator $H$ has a special name, the $\textbf{Hamiltonian}$ of the system. In fact, it is the measurement operator associated to the energy of the system.
\begin{definition}
    A measurement operator is a Hermitian operator $A$ for an observable $O$ %is an operator
    with (orthonormal) eigenstates $\ket{\psi_n}$ and eigenvalues $A_n$, where the former are states of definite $O$ value and $A_n$ are the values
    of $O$ you can observe.
\end{definition}
We are guaranteed the eigenstates of the Hermitian operator are orthonormal by the Spectral theorem, so this works with our idea of measurement before.
For the Hamiltonian, this means that we can refer to the eigenvectors $\ket{\psi_n}$'s as the states with definite energy, and the $E_n$'s as the energies of the corresponding states. They are related them via
\[ H \ket{\psi_n} = E_n \ket{\psi_n},\]
which is often called the \textbf{time-independent Schrodinger equation}. With this substitution, we obtain
\[ i \pdv{}{t} \ket{\psi(t)} = E_n \ket{\psi(t)} \implies \ket{\psi(t)} = e^{-i E_n t} \ket{\psi(0)} = e^{-i E_n t} \ket{\psi_n} \]
So essentially, Schrodinger's Equation tells us that the behavior for a given quantum state $\ket{\psi(t)}$ is characterized by its component states $\ket{\psi_n}$ precessing at a rate proportional to its energy $E_n$. 

\begin{example}
    Given initial state $\ket{\psi(0)} = \ket 0$ and operator $H = X = \begin{pmatrix}
        0 & 1 \\
        1 & 0 
    \end{pmatrix}$, find the general state $\ket{\psi(t)}$.

    \emph{Solution:} Since the eigenvector-value pairs of $H$ are $(\ket+, 1)$ and $(\ket-, -1)$, we express $\ket{\psi(0)}$ in terms of the eigenvectors of $H$ as follows:
    \[\ket{\psi(0)} = \ket 0 = \sum_n \alpha_n \ket{\psi_n} = \frac{1}{\sqrt{2}} \ket{+} + \frac{1}{\sqrt{2}} \ket -\]
    Now, we can compute $\ket{\psi(t)}$ as such:
    \begin{align*}
        \ket{\psi(t)} &= e^{-i H t} \ket{\psi(0)} \\
        &= \sum_n \alpha_n e^{-i E_n t} \ket{\psi_n} \\
        &= \frac{1}{\sqrt{2}} e^{-i \cdot 1 \cdot t} \ket{+} + \frac{1}{\sqrt{2}}e^{-i \cdot (-1) \cdot t} \ket - \\
        &= \frac{1}{\sqrt{2}} e^{-it} \ket{+} + \frac{1}{\sqrt{2}}e^{it} \ket -
    \end{align*}
    where we choose units such that $\hbar = 1$.
\end{example}
\subsection{Bloch Sphere}
Recall we tried to visualize $\alpha\ket{0} + \beta\ket{1}$ as living in a 2d Hilbert space. However, in general, the amplitudes are
complex, so such a picture is incomplete.

For the special case of a two-state system (e.g. a qubit), there exists a different visualization technique. Note that even though there are 2 complex numbers and thus 4 real
numbers of information, scaling by phase and magnitude does not change the state, i.e. $\ket{\psi} \equiv \lambda \ket{\psi}$ for any $\lambda \in \C$. Thus,
there are only $4 - 2 = 2$ real degrees of freedom. We normalize the state, taking the norm to be 1, and use the following form:
\[ \ket{\psi} = \cos \frac{\theta}{2} e^{i \chi} \ket{0} + \sin \frac{\theta}{2} e^{i \chi + i \phi} \ket{1} \]
Now we can remove the phase of $e^{i \chi}$ from each, so we get the state as 
\[ \ket{\psi} = \cos \frac{\theta}{2} \ket{0} + \sin \frac{\theta}{2} e^{i \phi} \ket{1} \]
where $\phi \in [0, 2\pi]$ and $\theta \in [0, \pi]$ (one period of all of these functions). If $\theta = 0$, then clearly $\phi$ is irrelevant because the second term is 0.
Similarly, if $\theta = \pi$, then clearly there is only a $\ket{1}$ term, which means that $\phi$ only creates a global phase, which doesn't change the state.

Hence, we call this the \textbf{Bloch Sphere} representation of the state $\ket{\psi}$. This is because it naturally maps a state to points on a sphere,
with $\theta$ as the polar angle and $\phi$ as the azimuthal angle in a standard spherical coordinate setup. The special cases above are the north ($\ket{0}$) and south pole ($\ket{1}$) separately, where at a pole your azimuthal angle doesn't matter.

Note that the poles we marked aren't special, and we can generalize the idea of ``poles'' to \textbf{antipodal points}:
\begin{definition}[Antipodal]
    Two points on the Bloch sphere are defined to be antipodal if the line segment connecting them crosses the center of the sphere.
\end{definition}
\begin{note}
    Given a state $\ket{\psi} = \cos \frac{\theta}{2} \ket 0 + e^{i \phi} \sin \frac{\theta}{2} \ket 1$, the state that is antipodal to it is 
    \[\ket{\psi^{\prime}} = \cos\left(\frac{\pi - \theta}{2}\right) \ket 0 + e^{i(\phi + \pi)} \sin\left(\frac{\pi - \theta}{2}\right) \ket 1\]
\end{note}
\begin{note}
    Orthogonal states always occur at antipodal (opposite) points on the Bloch sphere.
\end{note}
One can also observe that the states $\ket{\pm}$ and $\ket{\pm i} = \ftwo \qty(\ket{0} \pm i \ket{1})$ all live on the equator with $\theta = \frac{\pi}{2}$,
where $\ket{\pm}$ points in the direction of $\pm x$ and $\ket{\pm i}$ points in the direction of $\pm y$.

\subsection{Electron Spins}
One can think of electron spins as a two state system with basis $\ket{\uparrow} = \ket{0}$ and $\ket{\downarrow} = \ket{1}$
which correspond (roughly) to the direction an electron can spin (angular momentum in the $\pm z$ axis). You can also pick any direction $\mathbf{n}$
and find the component of the angular momentum in that direction. 

Classically, the spin will just be $\mathbf{n} \cdot \mathbf{z}$ and it will be some definite value.
However, in the world of quantum mechanics, by measuring in this direction, we can only get two possibilities: the spin being either parallel or antiparallel with $\mathbf{n}$.
One can use the Bloch sphere to understand this; associate $\ket{\mathbf{n}}$ with its representation on the Bloch sphere.
The state $\ket{\mathbf{n}}$ has definite angular momentum $L_{\mathbf{n}} = + \frac{1}{2}$ in the $\mathbf{n}$-direction, so it and its antipodal point $\ket{- \mathbf{n}}$ also form a basis for two state systems!

We can think of the operator for the measurement of momentum in the $z$ direction (i.e. the ``observable'') as follows:
\[ L_{\mathbf{z}} = \frac{1}{2} \ket{0} \bra{0} - \frac{1}{2} \ket{1} \bra{1} = \frac{1}{2} \begin{pmatrix}
    1 & 0 \\ 0 & -1
 \end{pmatrix} = \frac{1}{2} Z \]
Similarly, for measuring the $x$ momentum we have
\[ L_{\mathbf{x}} = \frac{1}{2} \ket{+} \bra{+} - \frac{1}{2} \ket{-} \bra{-} = \frac{1}{2} \begin{pmatrix}
    0 & 1 \\ 1 & 0
 \end{pmatrix} = \frac{1}{2} X \]
We know from physics that a magnetic field assigns a vector $\mathbf{B}$ to every point in space. Then, we can write the Hamiltonian (total energy) as:
\[ H = \frac{e}{m_e} \mathbf{L} \cdot \mathbf{B} \]
where $e$ and $m_e$ are the charge and mass of an electron, respectively.
For simplicity, we will say the magnetic field is constant and only in the $x$ direction: $\mathbf{B} = (B, 0, 0)$,
which means 
\[H = \frac{e}{m_e} BL_x = \frac{eB}{2m_e} X.\] 
Now that we know the Hamiltonian, we can figure out how such a system evolves in time. For our
initial condition, we set $\ket{\psi(0)} = \ket{\uparrow} = \ket{0}$, and write the general state as $\ket{\psi(t)} = \alpha(t) \ket{0} + \beta(t) \ket{1}$.
Rewriting Schrodinger's equation we get:
\begin{align*}
    i \dv{}{t} \ket{\psi(t)} &= H \ket{\psi(t)} \\
    i \dot{\alpha}(t) \ket{0} + i \dot{\beta}(t) \ket{1} &= \frac{eB}{2m_e} \qty(\alpha(t) X \ket{0} + \beta(t) X \ket{1}) \\
    i \dot{\alpha}(t) \ket{0} + i \dot{\beta}(t) \ket{1} &= \frac{eB}{2m_e} \qty(\beta(t) \ket{0} + \alpha(t) \ket{1})
\end{align*}
This gives us a differential equation for each component:
\[ \begin{cases} \dot{\alpha} = \frac{eB}{2m_e i} \beta \\ \dot{\beta} = \frac{eB}{2m_e i} \alpha \end{cases} \]
Taking the derivative with respect to $t$ in the first equation, we get that
\begin{align*}
    \ddot{\alpha} = \frac{eB}{2m_e i} \dot{\beta} = - \qty(\frac{eB}{2m_e})^2 \alpha
\end{align*}
This is a well-known ODE with solutions as $\sin$ and $\cos$. Note that $\alpha$ must be a cosine because it is initially $1$, so working it out gives us:
\[ \alpha(t) = \cos\qty(\frac{eB}{2m_e} t) \implies \beta(t) = \frac{2m_e}{eB} i \dot{\alpha} = - i \sin\qty(\frac{eB}{2m_e} t) \]
We can interpret this behavior as rotating around the bloch sphere, where the relative phase $\phi$ stays fixed at $\pi$ (or flips as we go back around) and $\theta$ moves at the angular velocity 
$\omega = \frac{eB}{2m_e}$, with period $\frac{\pi m_e}{eB}$.
The electron rotates down to $\ket{+i}$, then $\ket{1}$, and finally $\ket{-i}$. This is a rotation about the $x$-axis, where we put the magnetic field! This behavior is known as \textbf{spin precession}.

\subsubsection{Using Spin to Enable Quantum Computing}

How does this idea enable quantum computing? We know that we have to somehow change the Hamiltonian throughout time. To do this, we implement quantum gates by switching the magnetic field on and off in certain directions to create desired electron motion. For example, to implement a NOT gate, we leave magnetic field on for some
multiple of the period (plus one half phase) to make the spin precess until it hits the opposite pole, then switch off the magnetic field. This way, we're able to manipulate the behavior of quantum states.
